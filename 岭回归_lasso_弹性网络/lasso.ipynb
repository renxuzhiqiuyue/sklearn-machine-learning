{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.7 2.6 6.9 2.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.3 2.5 4.9 1.5]] \n",
      " [2 0 0 2 1] \n",
      " 测试集: \n",
      " [[6.1 3.  4.6 1.4]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.9 3.2 5.7 2.3]] \n",
      " [1 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "iris = datasets.load_iris() # 导入数据集\n",
    "X = iris.data # 获得其特征向量\n",
    "y = iris.target # 获得样本label\n",
    "\n",
    "# 分割数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n",
    "\n",
    "print(X_train[:5], '\\n', y_train[:5,], '\\n','测试集:','\\n', X_test[:3,:], '\\n', y_test[:3] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "# 1. 基于mean和std的标准化\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "train_data = scaler.transform(X_train)\n",
    "test_data = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型拟合和预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X_train, y_train, X_test, model, y_test = None):\n",
    "    # 拟合模型\n",
    "    model.fit(X_train, y_train)\n",
    "    # 模型预测\n",
    "    print(model.predict(X_test))\n",
    "    \n",
    "    # 获得这个模型的参数\n",
    "    print(model.get_params())\n",
    "    # 为模型进行打分\n",
    "    print('model得分(训练集）：',model.score(X_train, y_train)) # 线性回归：R square； 分类问题： acc\n",
    "    if y_test is not None:\n",
    "        print('model得分（测试集）：',model.score(X_test, y_test)) # 线性回归：R square； 分类问题： acc\n",
    "        # 显示综合指标\n",
    "        anwser=model.predict(X_test)\n",
    "        from sklearn.metrics import classification_report,accuracy_score, auc, confusion_matrix, f1_score, precision_score, recall_score\n",
    "        print(classification_report(y_test,anwser))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拟合模型\n",
    "model.fit(X_train, y_train)\n",
    "# 模型预测\n",
    "print(model.predict(X_test))\n",
    "\n",
    "# 获得这个模型的参数\n",
    "print(model.get_params())\n",
    "# 为模型进行打分\n",
    "print('model得分：',model.score(X_train, y_train)) # 线性回归：R square； 分类问题： acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正则化线性回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.32220517 1.39342326 0.14710657 1.25098707 0.25393372 1.50025041\n",
      " 0.21832467 1.28659612 1.60707756 1.6426866  1.50025041 0.21832467\n",
      " 1.25098707 1.21537802 0.14710657 0.21832467 1.6426866  0.18271562\n",
      " 1.28659612 1.42903231 0.75246039 1.28659612 1.74951375 1.28659612\n",
      " 0.28954276 0.14710657 1.32220517 1.82073185 1.35781422 0.28954276\n",
      " 1.46464136 1.82073185 0.21832467 1.46464136 0.14710657 1.42903231\n",
      " 0.93050564 1.42903231 1.67829565 1.35781422 1.00172373 1.35781422\n",
      " 0.18271562 1.53585946 1.32220517]\n",
      "{'alpha': 0.3, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'normalize': False, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}\n",
      "model得分(训练集）： 0.8850119309714172\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "model = Lasso(alpha=.3)\n",
    "names = iris[\"feature_names\"]\n",
    "\n",
    "fit(X_train, y_train, X_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L1正则化将系数w的l1范数作为惩罚项加到损失函数上，由于正则项非零，这就迫使那些弱的特征所对应的系数变成0。\n",
    "\n",
    "因此L1正则化往往会使学到的模型很稀疏（系数w经常为0），这个特性使得L1正则化成为一种很好的特征选择方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso model's ahlpha:  0.3                 0\n",
      "CRIM    -0.242279\n",
      "ZN       0.081819\n",
      "INDUS   -0.000000\n",
      "CHAS     0.539872\n",
      "NOX     -0.698913\n",
      "RM       2.993230\n",
      "AGE     -0.000000\n",
      "DIS     -1.080913\n",
      "RAD      0.000000\n",
      "TAX     -0.000000\n",
      "PTRATIO -1.755612\n",
      "B        0.628315\n",
      "LSTAT   -3.704633\n"
     ]
    }
   ],
   "source": [
    "# 另一个例子\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_boston\n",
    "  \n",
    "boston = load_boston()\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(boston[\"data\"])\n",
    "Y = boston[\"target\"]\n",
    "names = boston[\"feature_names\"]\n",
    "\n",
    "alpha = 0.3\n",
    "lasso = Lasso(alpha=alpha)\n",
    "lasso.fit(X, Y)\n",
    "\n",
    "def pretty_print_linear(coefs, names = None, sort = False):  \n",
    "    import pandas as pd\n",
    "    temp = pd.DataFrame(coefs, names)\n",
    "    return temp\n",
    "\n",
    "print(\"Lasso model's ahlpha: \",alpha , pretty_print_linear(lasso.coef_, names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L2正则化将系数向量的L2范数添加到了损失函数中。由于L2惩罚项中系数是二次方的，这使得L2和L1有着诸多差异，最明显的一点就是，L2正则化会让系数的取值变得平均。对于关联特征，这意味着他们能够获得更相近的对应系数。还是以Y=X1+X2为例，假设X1和X2具有很强的关联，如果用L1正则化，不论学到的模型是Y=X1+X2还是Y=2X1，惩罚都是一样的，都是2alpha。但是对于L2来说，第一个模型的惩罚项是2 alpha，但第二个模型的是4*alpha。可以看出，系数之和为常数时，各系数相等时惩罚是最小的，所以才有了L2会让各个系数趋于相同的特点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.31625124  1.4098341  -0.02024382  1.28648666  0.15397408  1.58446362\n",
      "  0.01293899  1.38232621  1.78571779  1.82478133  1.81087885 -0.00749258\n",
      "  1.27536326  1.22765446 -0.02794898 -0.05291986  1.74573899 -0.02454107\n",
      "  1.35755584  1.57061192  0.79311531  1.35640992  1.77143807  1.33054549\n",
      "  0.16533844 -0.02978374  1.37983778  1.88318019  1.38709508  0.10220898\n",
      "  1.5520048   2.09549136  0.01089843  1.5476724  -0.06653981  1.45412468\n",
      "  0.90897903  1.56038317  1.90312452  1.35442013  0.9871061   1.39369979\n",
      "  0.01677915  1.78683887  1.3500721 ]\n",
      "{'alpha': 10, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': False, 'random_state': None, 'solver': 'auto', 'tol': 0.001}\n",
      "model得分(训练集）： 0.940143000790545\n"
     ]
    }
   ],
   "source": [
    "# L2正则化/Ridge regression\n",
    "from sklearn.linear_model import Ridge\n",
    "model = Ridge(alpha=10)\n",
    "\n",
    "fit(X_train, y_train, X_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed 0\n",
      "Linear model:           0\n",
      "0  0.728440\n",
      "1  2.309260\n",
      "2 -0.082192\n",
      "Ridge model:           0\n",
      "0  0.938321\n",
      "1  1.058873\n",
      "2  0.876526\n",
      "Random seed 1\n",
      "Linear model:           0\n",
      "0  1.151816\n",
      "1  2.365799\n",
      "2 -0.599009\n",
      "Ridge model:           0\n",
      "0  0.984096\n",
      "1  1.067927\n",
      "2  0.758554\n"
     ]
    }
   ],
   "source": [
    "# 另一个例子\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "size = 100\n",
    "#We run the method 10 times with different random seeds\n",
    "for i in range(2):\n",
    "    print(\"Random seed %s\" % i)\n",
    "    np.random.seed(seed=i)\n",
    "    X_seed = np.random.normal(0, 1, size)\n",
    "    X1 = X_seed + np.random.normal(0, .1, size)\n",
    "    X2 = X_seed + np.random.normal(0, .1, size)\n",
    "    X3 = X_seed + np.random.normal(0, .1, size)\n",
    "    Y = X1 + X2 + X3 + np.random.normal(0, 1, size)\n",
    "    X = np.array([X1, X2, X3]).T\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X,Y)\n",
    "    print(\"Linear model:\", pretty_print_linear(lr.coef_))\n",
    "    ridge = Ridge(alpha=10)\n",
    "    ridge.fit(X,Y)\n",
    "    print(\"Ridge model:\", pretty_print_linear(ridge.coef_))\n",
    "    print"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
