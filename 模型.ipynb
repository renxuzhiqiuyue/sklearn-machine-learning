{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.7 2.6 6.9 2.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.3 2.5 4.9 1.5]] \n",
      " [2 0 0 2 1] \n",
      " 测试集: \n",
      " [[6.1 3.  4.6 1.4]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.9 3.2 5.7 2.3]] \n",
      " [1 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "iris = datasets.load_iris() # 导入数据集\n",
    "X = iris.data # 获得其特征向量\n",
    "y = iris.target # 获得样本label\n",
    "\n",
    "# 分割数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n",
    "\n",
    "print(X_train[:5], '\\n', y_train[:5,], '\\n','测试集:','\\n', X_test[:3,:], '\\n', y_test[:3] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "# 1. 基于mean和std的标准化\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "train_data = scaler.transform(X_train)\n",
    "test_data = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型拟合和预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X_train, y_train, X_test, model, y_test = None):\n",
    "    # 拟合模型\n",
    "    model.fit(X_train, y_train)\n",
    "    # 模型预测\n",
    "    print(model.predict(X_test))\n",
    "    \n",
    "    # 获得这个模型的参数\n",
    "    print(model.get_params())\n",
    "    # 为模型进行打分\n",
    "    print('model得分(训练集）：',model.score(X_train, y_train)) # 线性回归：R square； 分类问题： acc\n",
    "    if y_test is not None:\n",
    "        print('model得分（测试集）：',model.score(X_test, y_test)) # 线性回归：R square； 分类问题： acc\n",
    "        # 显示综合指标\n",
    "        anwser=model.predict(X_test)\n",
    "        from sklearn.metrics import classification_report,accuracy_score, auc, confusion_matrix, f1_score, precision_score, recall_score\n",
    "        print(classification_report(y_test,anwser))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拟合模型\n",
    "model.fit(X_train, y_train)\n",
    "# 模型预测\n",
    "print(model.predict(X_test))\n",
    "\n",
    "# 获得这个模型的参数\n",
    "print(model.get_params())\n",
    "# 为模型进行打分\n",
    "print('model得分：',model.score(X_train, y_train)) # 线性回归：R square； 分类问题： acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线性回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.21051493  1.30360611 -0.00628713  1.22231359  0.22868601  1.56726256\n",
      " -0.03428546  1.38096044  1.84255115  1.87825047  2.07150535 -0.07527829\n",
      "  1.22295999  1.17923241 -0.0218404  -0.14788095  1.71994611 -0.08054844\n",
      "  1.40034191  1.62002308  0.88542604  1.39352526  1.60216416  1.31396282\n",
      "  0.1904589  -0.01620439  1.34712674  1.7592645   1.33755197  0.0731164\n",
      "  1.53088587  2.26297305 -0.0429911   1.50854692 -0.12684239  1.36353337\n",
      "  0.87693494  1.62255847  2.00649912  1.24432525  0.94833357  1.33687459\n",
      "  0.02070654  1.94379854  1.3105583 ]\n",
      "{'copy_X': True, 'fit_intercept': True, 'n_jobs': 1, 'normalize': False}\n",
      "model得分(训练集）： 0.9484664413970854\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression(fit_intercept=True, normalize=False, \n",
    "    copy_X=True, n_jobs=1)\n",
    "\"\"\"\n",
    "参数\n",
    "---\n",
    "    fit_intercept：是否计算截距。False-模型没有截距\n",
    "    normalize： 当fit_intercept设置为False时，该参数将被忽略。 如果为真，则回归前的回归系数X将通过减去平均值并除以l2-范数而归一化。\n",
    "     n_jobs：指定线程数\n",
    "\"\"\"\n",
    "fit(X_train, y_train, X_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多项式回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.29807778  1.93899884  1.9526176   1.16859315 -0.03383056 -0.0222433\n",
      "  1.63357273  0.88206733  1.56834976  1.21124951  1.55543048  1.99331374\n",
      " -0.11684131  2.07528894  0.94513384  1.78076954  1.900731   -0.04085768\n",
      "  1.46582458  1.33114105 -0.01106339  1.96880017 -0.13455781  1.03801088\n",
      " -0.05586566  0.81948431  1.16499026  1.38115494  1.16860235 -0.09469044\n",
      " -0.04960794  1.72457002 -0.13462205  1.02544175  1.83487901  1.71332019\n",
      "  1.27133296  1.12567279  1.29995402  2.04771399  0.01026303  0.15092542\n",
      "  1.28002033  0.00560836  1.53903896]\n",
      "{'copy_X': True, 'fit_intercept': True, 'n_jobs': None, 'normalize': False}\n",
      "model得分(训练集）： 0.9306955508703275\n"
     ]
    }
   ],
   "source": [
    "# 从sklearn.preproessing中导入多项式特征产生器\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# 使用PolynominalFeatures(degree=2)映射出2次多项式特征，存储在变量X_train_poly2中。\n",
    "poly2 = PolynomialFeatures(degree=2)\n",
    "\n",
    "# 若训练集X_train 中不止一个因素，那么出现交叉效应，与方差分析相似\n",
    "X_train_poly2 = poly2.fit_transform(X_train)\n",
    "X_test_poly2 = poly2.fit_transform(X_test)\n",
    "# 以线性回归器为基础，初始化回归模型。尽管特征的维度有提升，但是模型基础仍然是线性模型。\n",
    "model = LinearRegression()\n",
    "\n",
    "fit(X_train, y_train, X_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 逻辑回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 2 1 0 0 2 1 2 1 2 2 0 2 1 2 2 0 2 1 0 2 0 1 0 1 1 2 1 0 0 2 0 1 2 2 1\n",
      " 1 1 2 0 0 1 0 2]\n",
      "{'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'ovr', 'n_jobs': 1, 'penalty': 'l2', 'random_state': None, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "model得分(训练集）： 0.9619047619047619\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# 定义逻辑回归模型\n",
    "model = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, \n",
    "    fit_intercept=True, intercept_scaling=1, class_weight=None, \n",
    "    random_state=None, solver='liblinear', max_iter=100, multi_class='ovr', \n",
    "    verbose=0, warm_start=False, n_jobs=1)\n",
    "\n",
    "\"\"\"参数\n",
    "---\n",
    "    penalty：使用指定正则化项（默认：l2）\n",
    "    dual: n_samples > n_features取False（默认）\n",
    "    C：正则化强度的反，值越小正则化强度越大\n",
    "    n_jobs: 指定线程数\n",
    "    random_state：随机数生成器\n",
    "    fit_intercept: 是否需要常量\n",
    "\"\"\"\n",
    "\n",
    "fit(X_train, y_train, X_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 2 1 0 0 2 1 1 1 2 2 0 2 1 2 2 0 2 1 0 2 0 1 0 1 1 1 1 0 0 2 0 1 2 2 1\n",
      " 1 1 2 0 0 1 0 2]\n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'presort': False, 'random_state': None, 'splitter': 'best'}\n",
      "model得分(训练集）： 1.0\n"
     ]
    }
   ],
   "source": [
    "# 决策树DT\n",
    "from sklearn import tree\n",
    "\n",
    "model = tree.DecisionTreeClassifier(criterion='gini', max_depth=None, \n",
    "    min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "    max_features=None, random_state=None, max_leaf_nodes=None, \n",
    "    min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "     class_weight=None)\n",
    "\n",
    "\"\"\"参数\n",
    "---\n",
    "    criterion ：特征选择准则gini/entropy\n",
    "    max_depth：树的最大深度，None-尽量下分\n",
    "    min_samples_split：分裂内部节点，所需要的最小样本树\n",
    "    min_samples_leaf：叶子节点所需要的最小样本数\n",
    "    max_features: 寻找最优分割点时的最大特征数\n",
    "    max_leaf_nodes：优先增长到最大叶子节点数\n",
    "    min_impurity_decrease：如果这种分离导致杂质的减少大于或等于这个值，则节点将被拆分。\n",
    "\"\"\"\n",
    "\n",
    "fit(X_train, y_train, X_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 2. 1. 0. 0. 2. 1. 1. 1. 2. 2. 0. 2. 1. 2. 2. 0. 2. 1. 0. 2. 0. 1.\n",
      " 0. 1. 1. 1. 1. 0. 0. 2. 0. 1. 2. 2. 1. 1. 1. 2. 0. 0. 1. 0. 2.]\n",
      "{'criterion': 'mse', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'presort': False, 'random_state': None, 'splitter': 'best'}\n",
      "model得分(训练集）： 1.0\n"
     ]
    }
   ],
   "source": [
    "# 回归树DTR\n",
    "from sklearn import tree\n",
    "model = tree.DecisionTreeRegressor()\n",
    "\n",
    "fit(X_train, y_train, X_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多层感知机分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 2 1 0 0 2 1 2 1 2 2 0 2 1 2 2 0 2 1 0 2 0 1 0 1 1 1 1 0 0 2 0 1 2 2 1\n",
      " 1 1 2 0 0 1 0 2]\n",
      "{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_iter': 200, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': None, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}\n",
      "model得分(训练集）： 0.9809523809523809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "# 定义多层感知机分类算法\n",
    "model = MLPClassifier(activation='relu', solver='adam', alpha=0.0001)\n",
    "\"\"\"参数\n",
    "---\n",
    "    hidden_layer_sizes: 元祖\n",
    "    activation：激活函数\n",
    "    solver ：优化算法{‘lbfgs’, ‘sgd’, ‘adam’}\n",
    "    alpha：L2惩罚(正则化项)参数。\n",
    "\"\"\"\n",
    "fit(X_train, y_train, X_test, model) # 不收敛警告"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 1, 0, 0, 2, 1, 2, 1, 2, 2, 0, 2, 1, 2, 2, 0, 2, 1, 0, 2,\n",
       "       0, 1, 0, 1, 1, 1, 1, 0, 0, 2, 0, 1, 2, 2, 1, 1, 1, 2, 0, 0, 1, 0,\n",
       "       2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# 保存模型\n",
    "with open('model.pickle', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# 读取模型\n",
    "with open('model.pickle', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'参数\\n---\\n    这个版本太新了，要退回旧版本。等以后更新处理\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "# 保存模型\n",
    "joblib.dump(model, 'model.pickle')\n",
    "\n",
    "#载入模型\n",
    "model = joblib.load('model.pickle')\n",
    "\"\"\"参数\n",
    "---\n",
    "    这个版本太新了，要退回旧版本。等以后更新处理\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
